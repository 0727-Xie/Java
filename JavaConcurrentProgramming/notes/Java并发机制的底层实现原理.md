<!-- GFM-TOC -->
*  [Java并发机制的底层实现原理](#Java并发机制的底层实现原理)
    * [volatile的应用](#volatile的应用)
        * [volatile的定义与实现原理](#volatile的定义与实现原理)
        * [volatile的使用优化](#volatile的使用优化)
    * [synchronized的实现原理与应用](#synchronized的实现原理与应用)
        * [synchronized的实现原理](#synchronized的实现原理)
        * [Java对象头](#Java对象头)
        * [锁的升级与对比](#锁的升级与对比)
<!-- GFM-TOC -->
# Java并发机制的底层实现原理
## volatile的应用
### volatile的定义与实现原理
volatile的两条实现原则:

(1)**Lock前缀指令会引起处理器缓存回写到内存**。
Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。
在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。
但是，在最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。
在锁操作时，总是在总线上声言LOCK#信号。
但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。
相反，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定，
**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据**。


(2)**一个处理器的缓存回写到内存会导致其他处理器的缓存无效**。
IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）控制协议去维护内部缓存和其他处理器缓存的一致性。
在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。
处理器使用**嗅探技术**保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。
例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，
而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，
在下次访问相同内存地址时，强制执行缓存行填充。

### volatile的使用优化
Java并发编程大师Doug lea在JDK 7的并发包里新增一个
**队列集合类LinkedTransferQueue**，
它在使用volatile变量时，用一种**追加字节的方式**来优化队列出队和入队的性能。

```java
/** 队列中的头部节点 */ 
private transient final PaddedAtomicReference<QNode> head;
/** 队列中的尾部节点 */ 
private transient final PaddedAtomicReference<QNode> tail; 

static final class PaddedAtomicReference <T> extends AtomicReference T> {  
    // 使用很多4个字节的引用追加到64个字节    
    Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe;   
    PaddedAtomicReference(T r) {        
        super(r);    
    } 
} 
public class AtomicReference <V> implements java.io.Serializable {   
    private volatile V value;     // 省略其他代码 
｝
```

* 为什么追加64字节能够提高并发编程的效率呢？

因为对于英特尔酷睿i7、酷睿、Atom和 NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的**高速缓存行是64个字节宽**，
不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，
在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，
会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，
而队列的入队和出队操作则需要不停修改头节点和尾节点，
所以在多处理器的情况下将会严重影响到队列的入队和出队效率。
**Doug lea使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，
使头、尾节点在修改时不会互相锁定**。

* 那么是不是在使用volatile变量时都应该追加到64字节呢？

不是的。在两种场景下不应该使用这种方式:

(1)**缓存行非64字节宽的处理器**。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。

(2)**共享变量不会被频繁地写**。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，
这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，
就没必要通过追加字节的方式来避免相互锁定。

## synchronized的实现原理与应用
利用synchronized实现同步的基础：Java中的每一个对象都可以作为锁。具体表现为以下3种形式:

(1)对于普通同步方法，锁是当前实例对象。

(2)对于静态同步方法，锁是当前类的Class对象。

(3)对于同步方法块，锁是Synchonized括号里配置的对象。

### synchronized的实现原理
从JVM规范中可以看到Synchonized在JVM里的实现原理，
JVM基于**进入和退出Monitor对象**来实现方法同步和代码块同步，但两者的实现细节不一样的。
**代码块同步是使用monitorenter 和monitorexit指令实现的**，而方法同步是使用另外一种方式实现的。
但是，方法的同步同样可以使用这两个指令来实现。
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，
JVM要保证每个monitorenter必须有对应的monitorexit与之配对。
任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。
线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

### Java对象头
synchronized用的锁是存在Java对象头里的。
如果对象是数组类型，则虚拟机用3个字宽 （Word）存储对象头，
如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。

Java对象头里的Mark Word里默认存储对象的**HashCode**、**分代年龄**和**锁标记位**。

在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。

### 锁的升级与对比
Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，
在 Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：
**无锁状态**、**偏向锁状态**、**轻量级锁状态**和**重量级锁状态**，
这几个状态会随着竞争情况逐渐升级。
锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。


* 偏向锁

大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。
当一个线程访问同步块并获取锁时，会在对象头和栈帧中的**锁记录里存储锁偏向的线程ID**，
以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的MarkWord里是否存储着指向当前线程的偏向锁:

(1)如果测试成功，表示线程已经获得了锁。

(2)如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（1表示当前是偏向锁）:

如果没有设置，则使用CAS竞争锁；

如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

* 偏向锁的撤销

偏向锁使用了一种**等到竞争出现才释放锁的机制**，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。
偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。
它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着:

如果线程不处于活动状态，则将对象头设置成无锁状态；

如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，
栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。

<div align="center"> <img src="pics//arts/arts_1.png" width="600"/> </div>